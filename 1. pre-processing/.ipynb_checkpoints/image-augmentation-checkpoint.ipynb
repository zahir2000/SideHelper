{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9169357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import re, glob\n",
    "from six import BytesIO\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.image import imread\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to csv with original dataset\n",
    "path_to_csv = \"sidehelper.csv\"\n",
    "\n",
    "# read csv dataset\n",
    "df = pd.read_csv(path_to_csv, header=None)\n",
    "\n",
    "# the original dataset has no columns; add column names\n",
    "df.rename(columns={0: \"type\", 1: \"path\", 2: \"label\", 3: \"XMin\",\n",
    "                   4: \"YMin\", 5: \"XMax\", 6: \"YMin\", 7: \"XMax\",\n",
    "                   8: \"YMax\", 9: \"XMin\", 10: \"YMax\"}, inplace=True)\n",
    "\n",
    "# apply image augmentation only to the training set\n",
    "df_train = df[df['type'] == \"TRAIN\"].copy()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe11a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty data frame for first round of image augmentation\n",
    "df_augmented_set0 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3640e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transformation properties\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "    A.ToGray(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "# p = probability of the transformation being applied\n",
    "# format = albumentations; read more here: https://albumentations.ai/docs/getting_started/bounding_boxes_augmentation/\n",
    "# min_visibility = ensures more than half of the object is visible in augmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce053b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group dataframe by image path;\n",
    "# since there may be 2 or more objects in one image, we don't want to augment same image more than once\n",
    "grouped = df_train.groupby('path')\n",
    "\n",
    "# iterate through each image path\n",
    "for path, group in grouped:\n",
    "    # read image\n",
    "    image = cv2.imread(path)\n",
    "    \n",
    "    # extract file_path and extension\n",
    "    file_path, file_extension = os.path.splitext(path)\n",
    "    \n",
    "    # extract file name from path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # create new image name to save as\n",
    "    # I changed the path from the original directory of images so they are not mixed up\n",
    "    augmented_img_path = 'some_path/'+file_name+\"_set0\"+file_extension\n",
    "\n",
    "    # to store bounding boxes for transforming\n",
    "    bboxes = []\n",
    "    \n",
    "    # iterate through each object in the image\n",
    "    for index, row in group.iterrows():\n",
    "        \n",
    "        # store the coordinates & label in the list\n",
    "        xmin = row['XMin'].iloc[0]\n",
    "        ymin = row['YMin'].iloc[0]\n",
    "        xmax = row['XMax'].iloc[0]\n",
    "        ymax = row['YMax'].iloc[0]\n",
    "        label = row['label']\n",
    "        bboxes.append([xmin, ymin, xmax, ymax, label])\n",
    "    \n",
    "    try:\n",
    "        # do the actual augmentation and store the augmented image and properties\n",
    "        transformed = transform(image=image, bboxes=bboxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "    except:\n",
    "        # some images cant be read by cv2, I found that matplotlib.image works for those\n",
    "        image = imread(path)\n",
    "        transformed = transform(image=image, bboxes=bboxes)\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "    \n",
    "    # retrieve augmented image height & width\n",
    "    img_h, img_w, _ = transformed_image.shape\n",
    "    \n",
    "    # if the tranformation was unsuccessful, the length of transformed_bboxes will be 0;\n",
    "    # we don't want to store original image if not augmented\n",
    "    if (len(transformed_bboxes) != 0):\n",
    "        \n",
    "        # if there were more than one object in the image, we have to iterate through each object\n",
    "        # and store it in the dictionary; then store it in the empty dataframe we created to store augmented image details\n",
    "        for i in range(len(transformed_bboxes)):\n",
    "            xmin, ymin, xmax, ymax, label = transformed_bboxes[i]\n",
    "            new_row = {\n",
    "                 'type':\"TRAIN\",\n",
    "                 'path':augmented_img_path,\n",
    "                 'label':label,\n",
    "                 'XMin':xmin,\n",
    "                 'YMin':ymin,\n",
    "                 'XMax':xmax,\n",
    "                 'YMax':ymax,\n",
    "                 }\n",
    "            df_augmented_set0 = df_augmented_set0.append(new_row, ignore_index=True)\n",
    "            \n",
    "        # write the transformed image to path\n",
    "        cv2.imwrite(augmented_img_path, transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58913d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store augmented images from round 2\n",
    "df_augmented_set1 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f41e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the only difference is we crop the image this time\n",
    "# I made four transform properties because some images are smaller than 640x640, etc. So we crop it to even lower resolution\n",
    "# width and height accepts int only, so we cannot supply %\n",
    "\n",
    "transform1 = A.Compose([\n",
    "    A.RandomCrop(width=640, height=640),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "    A.ToGray(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transform2 = A.Compose([\n",
    "    A.RandomCrop(width=600, height=600),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "    A.ToGray(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transform3 = A.Compose([\n",
    "    A.RandomCrop(width=480, height=480),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "    A.ToGray(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))\n",
    "\n",
    "transform4 = A.Compose([\n",
    "    A.RandomCrop(width=320, height=320),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "    A.PixelDropout(p=0.5),\n",
    "    A.ToGray(p=0.3),\n",
    "], bbox_params=A.BboxParams(format='albumentations', min_area=1024, min_visibility=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_train.groupby('path')\n",
    "\n",
    "for path, group in grouped:\n",
    "    try:\n",
    "        image = cv2.imread(path)\n",
    "        image_h, image_w, _ = image.shape\n",
    "    except AttributeError:\n",
    "        image = imread(path)\n",
    "        image_h, image_w, _ = image.shape    \n",
    "    \n",
    "    if (image_h >= 320 and image_w >= 320):\n",
    "        file_path, file_extension = os.path.splitext(path)\n",
    "        file_name = os.path.basename(file_path)\n",
    "        filepath = 'E:/Images/SideHelper-Augmented/'+file_name+\"_set1\"+file_extension\n",
    "\n",
    "        bboxes = []\n",
    "        for index, row in group.iterrows():\n",
    "            xmin = row['XMin'].iloc[0]\n",
    "            ymin = row['YMin'].iloc[0]\n",
    "            xmax = row['XMax'].iloc[0]\n",
    "            ymax = row['YMax'].iloc[0]\n",
    "            label = row['label']\n",
    "            bboxes.append([xmin, ymin, xmax, ymax, label])\n",
    "            \n",
    "        try:\n",
    "            if (image_w < 480 or image_h < 480):\n",
    "                transformed = transform4(image=image, bboxes=bboxes)\n",
    "            elif (image_w < 600 or image_h < 600):\n",
    "                transformed = transform3(image=image, bboxes=bboxes)\n",
    "            elif (image_w < 640 or image_h < 640):\n",
    "                transformed = transform2(image=image, bboxes=bboxes)\n",
    "            else:\n",
    "                transformed = transform1(image=image, bboxes=bboxes)\n",
    "        except:\n",
    "            image = imread(path)\n",
    "            if (image_w < 480 or image_h < 480):\n",
    "                transformed = transform4(image=image, bboxes=bboxes)\n",
    "            elif (image_w < 600 or image_h < 600):\n",
    "                transformed = transform3(image=image, bboxes=bboxes)\n",
    "            elif (image_w < 640 or image_h < 640):\n",
    "                transformed = transform2(image=image, bboxes=bboxes)\n",
    "            else:\n",
    "                transformed = transform1(image=image, bboxes=bboxes)\n",
    "\n",
    "        transformed_image = transformed['image']\n",
    "        transformed_bboxes = transformed['bboxes']\n",
    "\n",
    "        img_h, img_w, _ = transformed_image.shape\n",
    "\n",
    "        if (len(transformed_bboxes) != 0):\n",
    "            for i in range(len(transformed_bboxes)):\n",
    "                xmin, ymin, xmax, ymax, label = transformed_bboxes[i]\n",
    "                new_row = {\n",
    "                 'type':\"TRAIN\",\n",
    "                 'path':filepath,\n",
    "                 'label':label,\n",
    "                 'XMin':xmin,\n",
    "                 'YMin':ymin,\n",
    "                 'XMax':xmax,\n",
    "                 'YMax':ymax,\n",
    "                 }#\n",
    "                df_augmented_set1 = df_augmented_set1.append(new_row, ignore_index=True)\n",
    "                           \n",
    "            file_path, file_extension = os.path.splitext(path)\n",
    "            file_name = os.path.basename(file_path)\n",
    "            cv2.imwrite(filepath, transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d14a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we change the format of our csv: https://cloud.google.com/vision/automl/object-detection/docs/csv-format\n",
    "df_augmented_set0 = df_augmented_set0[[\"type\", \"path\", \"label\", \"XMin\", \"YMin\", \"XMax\", \"YMin\", \"XMax\", \"YMax\", \"XMin\", \"YMax\"]]\n",
    "df_augmented_set1 = df_augmented_set1[[\"type\", \"path\", \"label\", \"XMin\", \"YMin\", \"XMax\", \"YMin\", \"XMax\", \"YMax\", \"XMin\", \"YMax\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26052f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all dataframes\n",
    "df_sidehelper = pd.concat([df, df_augmented_set0, df_augmented_set1], ignore_index=True, sort=False)\n",
    "df_sidehelper.to_csv(\"sidehelper_final.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original: {}\\nAugmented: {}\".format(df_train.label.count(), df_sidehelper[df_sidehelper.type == 'TRAIN'].label.count()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
